{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ElP2eusfhPKUw70mAtLtEiF5vEr4K8-F",
      "authorship_tag": "ABX9TyPyZPS4VrvG9Ch9P4dAB42L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rjosh003-CS/Data-Mining-coursework/blob/main/dm_coursework_part_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2:**\n",
        "- **Objective:** Build the best predictive model for credit card default prediction using various machine learning algorithms.\n",
        "- **Tasks:**\n",
        "  - Use k-Nearest Neighbours, Decision Trees, Random Forest, Bagging, AdaBoost (or XGBoost), and SVM algorithms.\n",
        "  - Tune models using cross-validation on the training dataset.\n",
        "  - Select the best model and justify the choice.\n",
        "  - Evaluate the best model's performance on the test set.\n",
        "  - Include charts illustrating how accuracy varies with one numeric hyperparameter for each algorithm.\n",
        "- **Submission Requirements:** A Jupyter notebook named Part2 with code, comments, explanations, and results displayed. Additionally, include charts for hyperparameter tuning.\n",
        "\n",
        "**Submission Details:**\n",
        "- **Teamwork:** Work in teams of two, with one team leader coordinating the submission.\n",
        "- **Individual Work:** If working alone, only tackle Part 1 and three algorithms from Part 2.\n",
        "- **Submission:** Team leader submits the assignment from their account, mentioning both team members' names and student numbers at the top of each notebook. If working alone, include a note indicating so.\n",
        "- **Deadline:** Ensure timely submission as per the course guidelines.\n",
        "\n",
        "Both parts emphasize coding, explanation, and analysis, with the second part requiring the exploration of multiple machine learning algorithms and model tuning for predictive performance."
      ],
      "metadata": {
        "id": "-b0fh1dDDTTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Credit Risk Data\n"
      ],
      "metadata": {
        "id": "GtKDybozcG5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1></h1>\n",
        "<h1 align = \"center\">Final Year Project - Section #number<h1>\n",
        "<h1 align = \"center\">#Topic<h1>\n",
        "\n",
        "<br>\n",
        "<h2 align = \"center\">Abstract</h2>\n",
        "<br>\n",
        "\n",
        " <p align = \"center\">\n",
        "    <i>\n",
        "      # Topic in brief\n",
        "    </i>\n",
        "    <br>\n",
        "    <quote>\n",
        "       \"# brief dicussion on the Objective\"\n",
        "    </quote>\n",
        "</p>\n",
        "\n",
        "<br>\n",
        "\n",
        "<p><b>Author:</b><span> Rohit Joshi <span></p>\n",
        "<p><b>email:</b><span> rjosh003@campus.goldsmiths.ac.uk </span></p>\n"
      ],
      "metadata": {
        "id": "LnwVKHnhw6Yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Introduction"
      ],
      "metadata": {
        "id": "JjO70jOFzAWH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Definition of the problem\n"
      ],
      "metadata": {
        "id": "K4RCs9THzFA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### <font color = yellow> <u>Areas of Concern</u>: </font>\n",
        "\n",
        "- 1. There would be class imbalance between the number of defaults over no defaults instances.\n",
        "\n",
        "<br>\n",
        "\n",
        "- 2. Handle the Class imbalance for the same.\n",
        "  \n",
        "  <br>\n",
        "\n",
        "  - 2.1 Cost-sensitive classification (using cost matrix)\n",
        "    - 2.1.1 chose lower cost model\n",
        "  \n",
        "  <br>\n",
        "\n",
        "  - 2.2 Modify the distribution of training data so that rare class is well-represented in training set.\n",
        "\n",
        "    - 2.2.1 Under-sample the majority class\n",
        "\n",
        "    - 2.2.2 Oversample the rare class\n",
        "\n",
        "  <br>\n",
        "\n",
        "  - 2.3 Advantages and disadvantages\n",
        "    \n",
        "    - 2.3.1 Making minority class instances counting more.\n",
        "    - 2.3.2 Sampling: Loosing some of data (of majority class)\n",
        "    - 2.3.3 Sampling: multiply weights: Training data may be less representative of real daa distribution - so keep original data proportion in the test data.\n",
        "    - Cost: affecting probability computation.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r2ePwJ-jcuGH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2M8yKZkF1I-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 About the Dataset"
      ],
      "metadata": {
        "id": "gOUSsBAqzV_x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Evaluation Metrics"
      ],
      "metadata": {
        "id": "aNWw9y72zcsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Data Processing\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "d2PBXRl7zuSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Data Pre-processing"
      ],
      "metadata": {
        "id": "QARYJ8gTzuIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Data Loading"
      ],
      "metadata": {
        "id": "sJ0Qx90vzsEb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwR188te4_WX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Data Cleaning"
      ],
      "metadata": {
        "id": "U8brMRob0nGj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PoIyzVub4_Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Features Engineering"
      ],
      "metadata": {
        "id": "byICrybP0slg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LDGE8yYQ4-zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Train-Validation-Test Split"
      ],
      "metadata": {
        "id": "C3lxvvQ40sEs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B8UIGl1x4-gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5 Normalization/Scaling\n",
        "- **Feature Scaling:** Normalize/standardize input features to a similar scale to prevent dominance by certain features during model training.\n",
        "  - Techniques StandardScaler is applied to the features."
      ],
      "metadata": {
        "id": "NJ6FAhKh1lCS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmcNspSd45Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6 Data Formatting\n",
        "- **Convert to Suitable Format:** Organize the data into sequences or time windows (if using recurrent neural networks or time series models).\n",
        "- **Convert to Arrays or Tensors:** Transform the data into arrays or tensors compatible with the chosen machine learning or deep learning framework."
      ],
      "metadata": {
        "id": "pb3rM3h31jUG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ods5sLNB45xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2.7 Data Pipeline Creation (Optional)\n",
        "- **Pipeline Construction:** Construct a data processing pipeline to automate and streamline the preprocessing steps, ensuring consistency across different datasets and reducing code redundancy."
      ],
      "metadata": {
        "id": "WQHxoFhE1jJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yxUMHjSj46Nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.8 Save Processed Data (optional)\n",
        "- **Save Processed Data:** Save the processed datasets (training, validation, test) in a suitable format (CSV, HDF5, etc.) for easy access during model training and evaluation.\n"
      ],
      "metadata": {
        "id": "4FECqslj0rvA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPDWmpb246ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 Methodology"
      ],
      "metadata": {
        "id": "_cejLsIh21J4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Finding the Common Sense Baseline"
      ],
      "metadata": {
        "id": "HEJj7I5T3ocS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "naJULuyp47WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Developing the First Model with Statistical Power"
      ],
      "metadata": {
        "id": "dCTeex8V31yG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XrGXZZmf3Pjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "H9-kMm2i4bN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bHE3zJVe42-U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3iOn9EC42i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "hSa10Z_E4a_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference"
      ],
      "metadata": {
        "id": "vgoJPHjx4mlo"
      }
    }
  ]
}